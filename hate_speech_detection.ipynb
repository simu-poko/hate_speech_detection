{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SpatialDropout1D, Dropout, Flatten, Dense, LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로딩 / データのロード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data can be downloaded from:\n",
    "- https://www.kaggle.com/vkrahul/twitter-hate-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_tweets.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리 / データの前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a function to convert contractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_contractions(tweet):\n",
    "    tweet = re.sub(\"won\\'t\", \"will not\", tweet)\n",
    "    tweet = re.sub(\"can\\'t\", \"can not\", tweet)\n",
    "    tweet = re.sub(\"\\'re\", \" are\", tweet)\n",
    "    tweet = re.sub(\"\\'ve\", \" have\", tweet)\n",
    "    tweet = re.sub(\"\\'ll\", \" will\", tweet)\n",
    "    tweet = re.sub(\"\\'d\", \" would\", tweet)\n",
    "    tweet = re.sub(\"n\\'t\", \" not\", tweet)\n",
    "    tweet = re.sub(r\"\\'s\", \" is\", tweet)\n",
    "    tweet = re.sub(r\"\\'m\", \" am\", tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a pre-processing function to remove unnecessary characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = re.sub(\"((www\\.[^\\s]+)|(https?://[^\\s]+))\", \"\", tweet.lower())  # remove URLs\n",
    "    tweet = re.sub(\"@[^\\s]+\", '', tweet)  # remove mentions\n",
    "    tweet = re.sub(\"#\\w*\", \"\", tweet)  # remove hashtags\n",
    "    tweet = convert_contractions(tweet)  # convert contractions\n",
    "    tweet = re.sub(\"[^0-9A-Za-z ]\", \"\", tweet)  # remove special characters and punctuations\n",
    "    tweet = re.sub(\"\\s{2,}\", \" \", tweet)  # remove spaces\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>when a father is dysfunctional and is so self...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks for credit i can not use cause they do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i love u take with u all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society now</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   when a father is dysfunctional and is so self...\n",
       "1   2      0   thanks for credit i can not use cause they do...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0           i love u take with u all the time in ur \n",
       "4   5      0                            factsguide society now "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tweet\"] = df[\"tweet\"].apply(preprocess_tweet)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. scikit-learn을 이용한 기계학습 / scikit-learnを用いた機械学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"tweet\"], df[\"label\"], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BernoulliNB()\n",
    "model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The recall of the hate speech class was 0.11 i.e. only about 10% of the actual hate speech could be detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7460\n",
      "           1       0.85      0.11      0.20       531\n",
      "\n",
      "    accuracy                           0.94      7991\n",
      "   macro avg       0.89      0.56      0.58      7991\n",
      "weighted avg       0.93      0.94      0.92      7991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The f1-score of the hate speech class was increased because the detection rate(=recall) of hate speech was improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      7460\n",
      "           1       0.82      0.43      0.56       531\n",
      "\n",
      "    accuracy                           0.96      7991\n",
      "   macro avg       0.89      0.71      0.77      7991\n",
      "weighted avg       0.95      0.96      0.95      7991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. keras를 이용한 기계학습 / kerasを用いた機械学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"tweet\"], df[\"label\"], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vectorize texts and convert to sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[138, 28, 14, 4686],\n",
       " [153, 16, 291],\n",
       " [436, 275, 12, 3, 24, 57, 265, 266, 265, 266]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train.values)\n",
    "x_train = tokenizer.texts_to_sequences(X_train.values)\n",
    "x_test = tokenizer.texts_to_sequences(X_test.values)\n",
    "x_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pad the sequences to the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,  138,   28,   14, 4686],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,  153,   16,  291]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pad_sequences(x_train)\n",
    "x_test = pad_sequences(x_test)\n",
    "x_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Embedding layer is defined as the first hidden layer of a network.\n",
    "- input_dim: This is the size of the vocabulary in the text data.\n",
    "- output_dim: This is the size of the vector space in which words will be embedded.\n",
    "- input_length: This is the length of input sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- units: This is the number of hidden units of the lstm layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embed_dim = 100\n",
    "lstm_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 33, 100)           2036300   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 33, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 2,066,551\n",
      "Trainable params: 2,066,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=x_train.shape[1]))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(units=lstm_dim))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21573 samples, validate on 2398 samples\n",
      "Epoch 1/5\n",
      "21573/21573 [==============================] - 29s 1ms/step - loss: 0.2050 - accuracy: 0.9369 - val_loss: 0.1809 - val_accuracy: 0.9429\n",
      "Epoch 2/5\n",
      "21573/21573 [==============================] - 30s 1ms/step - loss: 0.1025 - accuracy: 0.9631 - val_loss: 0.1896 - val_accuracy: 0.9441\n",
      "Epoch 3/5\n",
      "21573/21573 [==============================] - 30s 1ms/step - loss: 0.0557 - accuracy: 0.9817 - val_loss: 0.2063 - val_accuracy: 0.9395\n",
      "Epoch 4/5\n",
      "21573/21573 [==============================] - 29s 1ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 0.2621 - val_accuracy: 0.9383\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x236f4dfac18>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "early_stopping = EarlyStopping(patience=3, verbose=1) \n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "         validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compared to random forest, recall was increased at the expense of precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      7460\n",
      "           1       0.66      0.49      0.56       531\n",
      "\n",
      "    accuracy                           0.95      7991\n",
      "   macro avg       0.81      0.74      0.77      7991\n",
      "weighted avg       0.94      0.95      0.95      7991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test, batch_size=batch_size)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN using pretrained word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- See this page.\n",
    "- https://keras.io/examples/pretrained_word_embeddings/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open(\"glove.6B.100d.txt\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embed_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, embed_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- filters: This is the number of filters in the convolution. (= the dimensionality of the output)\n",
    "- kernel_size: This is the length of the 1D convolution window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 128\n",
    "kernel_size = 5\n",
    "dense_hidden_dim = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you want to connect a dense layer, you must flatten the 2D output matrix to the 1D vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 33, 100)           2036300   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 29, 128)           64128     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,117,069\n",
      "Trainable params: 80,769\n",
      "Non-trainable params: 2,036,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=x_train.shape[1],\n",
    "          embeddings_initializer=Constant(embedding_matrix), trainable=False))\n",
    "model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation=\"relu\"))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(units=dense_hidden_dim, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21573 samples, validate on 2398 samples\n",
      "Epoch 1/5\n",
      "21573/21573 [==============================] - 4s 195us/step - loss: 0.2002 - accuracy: 0.9354 - val_loss: 0.1741 - val_accuracy: 0.9399\n",
      "Epoch 2/5\n",
      "21573/21573 [==============================] - 4s 183us/step - loss: 0.1409 - accuracy: 0.9511 - val_loss: 0.1870 - val_accuracy: 0.9374\n",
      "Epoch 3/5\n",
      "21573/21573 [==============================] - 4s 181us/step - loss: 0.1017 - accuracy: 0.9652 - val_loss: 0.1878 - val_accuracy: 0.9383\n",
      "Epoch 4/5\n",
      "21573/21573 [==============================] - 4s 181us/step - loss: 0.0653 - accuracy: 0.9776 - val_loss: 0.2043 - val_accuracy: 0.9487\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b660063f98>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "early_stopping = EarlyStopping(patience=3, verbose=1) \n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "         validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can get a model with similar performance much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      7460\n",
      "           1       0.65      0.49      0.56       531\n",
      "\n",
      "    accuracy                           0.95      7991\n",
      "   macro avg       0.81      0.74      0.77      7991\n",
      "weighted avg       0.94      0.95      0.95      7991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test, batch_size=batch_size)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 결과 확인 / 結果確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(X_test, columns=[\"tweet\"])\n",
    "result[\"label\"] = y_test\n",
    "result[\"label_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data predicted as hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>label_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24123</th>\n",
       "      <td>your comments are reflections of ignorance and</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>that rudd woman should think b4 she speaks a statement was asked for all she could do was try and stick the boot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13251</th>\n",
       "      <td>they are adopting the worst traits of america</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3775</th>\n",
       "      <td>buffalo parents rally to remove trump ally carl paladino from school board after remarks</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>yes it is when you call a gorilla because racists have long thought of black people as no bet</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10756</th>\n",
       "      <td>hahaha wow that is a statement from a 21 year old browns fan who is never seen a browns playoff game</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13630</th>\n",
       "      <td>why would there be any reason to call out of her name haters</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15624</th>\n",
       "      <td>trump real estate buddy carl paladino wishes obama dead of mad cow disease in 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15420</th>\n",
       "      <td>south sudan allowed soldiers to rape as wages un</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31907</th>\n",
       "      <td>love that your statements came from the man who was rebuked by voters in 2008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                   tweet  \\\n",
       "24123   your comments are reflections of ignorance and                                                                     \n",
       "4534    that rudd woman should think b4 she speaks a statement was asked for all she could do was try and stick the boot   \n",
       "13251  they are adopting the worst traits of america                                                                       \n",
       "3775    buffalo parents rally to remove trump ally carl paladino from school board after remarks                           \n",
       "151    yes it is when you call a gorilla because racists have long thought of black people as no bet                       \n",
       "10756   hahaha wow that is a statement from a 21 year old browns fan who is never seen a browns playoff game               \n",
       "13630  why would there be any reason to call out of her name haters                                                        \n",
       "15624  trump real estate buddy carl paladino wishes obama dead of mad cow disease in 2017                                  \n",
       "15420   south sudan allowed soldiers to rape as wages un                                                                   \n",
       "31907   love that your statements came from the man who was rebuked by voters in 2008                                      \n",
       "\n",
       "       label  label_pred  \n",
       "24123  1      1           \n",
       "4534   0      1           \n",
       "13251  0      1           \n",
       "3775   1      1           \n",
       "151    1      1           \n",
       "10756  0      1           \n",
       "13630  0      1           \n",
       "15624  1      1           \n",
       "15420  0      1           \n",
       "31907  0      1           "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "result.loc[result[\"label_pred\"] == 1].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data predicted as hate speech, but not actually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>label_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>that rudd woman should think b4 she speaks a statement was asked for all she could do was try and stick the boot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13251</th>\n",
       "      <td>they are adopting the worst traits of america</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10756</th>\n",
       "      <td>hahaha wow that is a statement from a 21 year old browns fan who is never seen a browns playoff game</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13630</th>\n",
       "      <td>why would there be any reason to call out of her name haters</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15420</th>\n",
       "      <td>south sudan allowed soldiers to rape as wages un</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31907</th>\n",
       "      <td>love that your statements came from the man who was rebuked by voters in 2008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24603</th>\n",
       "      <td>the useful idiots on the left are being duped by the alinskyites into giving up the second amendment</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>watching the leadership embrace amp kiss donald is ass is amp this is now the pay a pay of racism amp hate</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>nude rear naughty naked school girls</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11136</th>\n",
       "      <td>nigel farage this is not a happy europe ukip leader nigel farage has suggested that peace in europ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                   tweet  \\\n",
       "4534    that rudd woman should think b4 she speaks a statement was asked for all she could do was try and stick the boot   \n",
       "13251  they are adopting the worst traits of america                                                                       \n",
       "10756   hahaha wow that is a statement from a 21 year old browns fan who is never seen a browns playoff game               \n",
       "13630  why would there be any reason to call out of her name haters                                                        \n",
       "15420   south sudan allowed soldiers to rape as wages un                                                                   \n",
       "31907   love that your statements came from the man who was rebuked by voters in 2008                                      \n",
       "24603   the useful idiots on the left are being duped by the alinskyites into giving up the second amendment               \n",
       "335    watching the leadership embrace amp kiss donald is ass is amp this is now the pay a pay of racism amp hate          \n",
       "2407    nude rear naughty naked school girls                                                                               \n",
       "11136   nigel farage this is not a happy europe ukip leader nigel farage has suggested that peace in europ                 \n",
       "\n",
       "       label  label_pred  \n",
       "4534   0      1           \n",
       "13251  0      1           \n",
       "10756  0      1           \n",
       "13630  0      1           \n",
       "15420  0      1           \n",
       "31907  0      1           \n",
       "24603  0      1           \n",
       "335    0      1           \n",
       "2407   0      1           \n",
       "11136  0      1           "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loc[(result[\"label_pred\"] == 1) & (result[\"label\"] != result[\"label_pred\"])].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
